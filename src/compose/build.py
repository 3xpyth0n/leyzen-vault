"""Compose manifest builder for Leyzen Vault."""

from __future__ import annotations

# ruff: noqa: E402

import json
import os
import sys
from collections import OrderedDict
from pathlib import Path
from typing import Mapping

# Bootstrap minimal to enable importing common.path_setup
# This must be done before importing common modules
# Standard pattern: Manually add src/ to sys.path, then use bootstrap_entry_point()
# Note: This local calculation is ONLY needed for the initial bootstrap before
# common.constants can be imported. After bootstrap, use SRC_DIR from common.constants.
# The calculation is necessary to avoid circular import dependencies.
_SRC_DIR = Path(__file__).resolve().parent.parent.parent / "src"
if str(_SRC_DIR) not in sys.path:
    sys.path.insert(0, str(_SRC_DIR))

from common.path_setup import bootstrap_entry_point

# Complete the bootstrap sequence (idempotent)
bootstrap_entry_point()

from compose.base_stack import (
    BASE_NETWORKS,
    BASE_VOLUMES,
    build_base_services,
    prepare_ssl_certificate_bundle,
    validate_ssl_certificates,
)
from compose.haproxy_config import render_haproxy_config_vault
from common.constants import HAPROXY_CONFIG_PATH, REPO_ROOT
from common.env import (
    load_env_with_override,
    parse_container_names,
    resolve_env_file_name,
)

# Auto-generated Docker Compose configuration file.
# This file is generated by build.py and should not be edited manually.
# Any manual changes will be overwritten when the build script runs.
OUTPUT_FILE = REPO_ROOT / "docker-generated.yml"

VAULT_WEB_PORT = 80
VAULT_MIN_REPLICAS = 2


def _parse_port(
    env: Mapping[str, str],
    key: str,
    default: int,
    min_value: int = 1,
    max_value: int = 65535,
) -> int:
    """Parse a port number from environment variable with validation."""
    raw_value = env.get(key, "").strip()
    if not raw_value:
        return default
    try:
        port = int(raw_value)
        port = max(min_value, min(max_value, port))
        return port
    except ValueError:
        return default


def resolve_web_containers(env: Mapping[str, str]) -> tuple[list[str], str]:
    """Resolve web container names from environment."""
    # Check if orchestrator is enabled
    orchestrator_enabled_raw = env.get("ORCHESTRATOR_ENABLED", "true").strip().lower()
    orchestrator_enabled = orchestrator_enabled_raw in ("true", "1", "yes", "on")

    # If orchestrator is disabled, use single vault_app container
    if not orchestrator_enabled:
        return ["vault_app"], "vault_app"

    env_value = env.get("ORCH_WEB_CONTAINERS", "").strip()
    if env_value:
        names = parse_container_names(env_value)
        if names:
            return names, env_value

    # Default: generate vault_web1, vault_web2, vault_web3
    replicas_raw = env.get("WEB_REPLICAS", "3").strip()
    try:
        replicas = max(VAULT_MIN_REPLICAS, int(replicas_raw))
    except ValueError:
        replicas = VAULT_MIN_REPLICAS

    names = [f"vault_web{i+1}" for i in range(replicas)]
    return names, ",".join(names)


def build_postgres_service(env: Mapping[str, str]) -> dict:
    """Build PostgreSQL service definition.

    Note on POSTGRES_PASSWORD validation:
    This function uses Docker Compose's environment variable substitution syntax
    (${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD in .env}) to ensure that the password
    is set at Docker Compose startup time. This provides an early validation layer
    that prevents the PostgreSQL container from starting without a password.

    However, this is a secondary validation. The primary validation happens in
    src/vault/config.py::get_postgres_url(), which is called when the Vault application
    starts and raises a ConfigurationError if POSTGRES_PASSWORD is missing or empty.
    This two-layer validation ensures that:
    1. Docker Compose fails fast if the password is not set (infrastructure level)
    2. The application fails with a clear error message if the password is invalid (application level)

    Both validations are necessary because:
    - Docker Compose validation prevents containers from starting with invalid configuration
    - Application validation provides better error messages and handles runtime configuration changes
    """
    env_file_name = resolve_env_file_name(REPO_ROOT)

    # Parse PostgreSQL configuration from environment
    postgres_db = env.get("POSTGRES_DB", "leyzen_vault").strip()
    postgres_user = env.get("POSTGRES_USER", "leyzen").strip()
    postgres_password = env.get("POSTGRES_PASSWORD", "").strip()
    postgres_port = _parse_port(env, "POSTGRES_PORT", default=5432)

    # Use environment variable reference for password
    # This provides Docker Compose-level validation (secondary validation)
    # Primary validation happens in src/vault/config.py::get_postgres_url()
    postgres_password_ref = "${POSTGRES_PASSWORD:?Set POSTGRES_PASSWORD in .env}"

    postgres_data_volume = env.get("POSTGRES_DATA_VOLUME", "postgres-data").strip()

    postgres_service = {
        "image": "postgres:16-alpine",
        "container_name": "postgres",
        "restart": "on-failure",
        "env_file": [env_file_name],
        "environment": {
            "POSTGRES_DB": postgres_db,
            "POSTGRES_USER": postgres_user,
            "POSTGRES_PASSWORD": postgres_password_ref,
            "POSTGRES_HOST_AUTH_METHOD": "scram-sha-256",
        },
        "expose": [f"{postgres_port}"],
        "volumes": [
            f"{postgres_data_volume}:/var/lib/postgresql/data",
            "./infra/postgres/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh:ro",
        ],
        "healthcheck": {
            "test": [
                "CMD-SHELL",
                "pg_isready -U ${POSTGRES_USER:-leyzen} -d postgres || exit 1",
            ],
            "interval": "2s",
            "timeout": "5s",
            "retries": 10,
            "start_period": "30s",
        },
        "networks": ["vault-net"],
    }

    return postgres_service


def build_vault_services(
    env: Mapping[str, str], web_containers: list[str]
) -> OrderedDict[str, dict]:
    """Build Vault service definitions.

    Vault Service Dependencies:
    - HAProxy (service_healthy): Vault containers need HAProxy to be healthy
      before starting to ensure proper routing configuration
    - PostgreSQL (service_healthy): Vault containers require database access
      for user data, file metadata, and audit logs

    Each vault container gets:
    - Direct tmpfs mount for ephemeral storage (MTD rotation) with security options
    - Shared source volume for data synchronization
    - Health checks to ensure readiness before receiving traffic
    """
    env_file_name = resolve_env_file_name(REPO_ROOT)

    # Get tmpfs size from environment variable (default: 1024 MB = 1GB)
    tmpfs_size_mb_raw = env.get("VAULT_MAX_TOTAL_SIZE_MB", "1024").strip()
    try:
        tmpfs_size_mb = max(1, int(tmpfs_size_mb_raw))
    except ValueError:
        tmpfs_size_mb = 1024  # Default to 1GB if invalid value

    services: OrderedDict[str, dict] = OrderedDict()

    for container_name in web_containers:
        service_def = {
            "build": {
                "context": ".",
                "dockerfile": "./infra/vault/Dockerfile",
            },
            "image": "leyzen/vault:latest",
            "container_name": container_name,
            "env_file": [env_file_name],
            "restart": "on-failure",
            "healthcheck": {
                "test": [
                    "CMD-SHELL",
                    "python3 /app/infra/vault/healthcheck.py || exit 1",
                ],
                "interval": "1s",
                "timeout": "2s",
                "retries": 2,
                "start_period": "5s",
            },
            "tmpfs": [
                f"/data:size={tmpfs_size_mb}M,noexec,nosuid,nodev",
            ],
            "volumes": [
                "vault-data-source:/data-source:rw",
                "./src/common:/common:ro",
            ],
            # Dependencies: Vault containers must wait for HAProxy and PostgreSQL
            # to be healthy before starting to ensure proper routing and database access
            "depends_on": {
                "haproxy": {"condition": "service_healthy"},
                "postgres": {"condition": "service_healthy"},
            },
            "networks": ["vault-net"],
            "stop_grace_period": "2s",
        }
        services[container_name] = service_def

    return services


def build_vault_volumes(web_containers: list[str]) -> OrderedDict[str, dict]:
    """Build volume definitions for Vault services.

    Note: tmpfs volumes are now mounted directly in services using the tmpfs option,
    so we only need to define the shared source volume here.

    The vault-data-source volume is marked as external with a fixed name to ensure
    persistence across Docker Compose project name changes and prevent accidental
    volume recreation.
    """
    volumes: OrderedDict[str, dict] = OrderedDict()

    # Source volume (read-only, shared) - persistent volume
    # Use fixed name to ensure persistence across restarts and prevent
    # recreation if Docker Compose project name changes.
    # Docker Compose will create the volume if it doesn't exist.
    volumes["vault-data-source"] = {
        "name": "leyzen-vault-data-source",
    }

    # Note: tmpfs volumes are mounted directly in services using tmpfs option
    # This provides better security and avoids volume driver issues

    return volumes


def build_compose_manifest(
    env: Mapping[str, str],
    *,
    web_containers: list[str] | None = None,
    web_container_string: str | None = None,
    ssl_cert_bundle_path: Path | None = None,
) -> OrderedDict[str, object]:
    """Construct the docker-compose manifest for Leyzen Vault."""

    if web_containers is None or web_container_string is None:
        web_containers, web_container_string = resolve_web_containers(env)

    # Check if orchestrator is enabled
    orchestrator_enabled_raw = env.get("ORCHESTRATOR_ENABLED", "true").strip().lower()
    orchestrator_enabled = orchestrator_enabled_raw in ("true", "1", "yes", "on")

    base_services = build_base_services(
        env,
        web_containers,
        web_container_string,
        ssl_cert_bundle_path=ssl_cert_bundle_path,
        orchestrator_enabled=orchestrator_enabled,
    )
    vault_services = build_vault_services(env, web_containers)
    vault_volumes = build_vault_volumes(web_containers)
    postgres_service = build_postgres_service(env)

    services: OrderedDict[str, dict] = OrderedDict()
    # Add PostgreSQL first (other services depend on it)
    services["postgres"] = postgres_service
    # Add vault services next
    for name, definition in vault_services.items():
        services[name] = definition
    # Then add base services (haproxy, docker-proxy, orchestrator)
    for name, definition in base_services.items():
        services[name] = definition

    # Add PostgreSQL volume
    postgres_volume_name = env.get("POSTGRES_DATA_VOLUME", "postgres-data").strip()
    postgres_volume = {postgres_volume_name: {"name": "leyzen-vault-postgres-data"}}

    volumes: OrderedDict[str, dict[str, object]] = OrderedDict()
    # Add PostgreSQL volume first
    volumes.update(postgres_volume)
    # Then add other volumes
    for collection in (vault_volumes, BASE_VOLUMES):
        for name, definition in collection.items():
            volumes[name] = dict(definition)

    networks: OrderedDict[str, dict[str, object]] = OrderedDict()
    networks.update(BASE_NETWORKS)

    manifest: OrderedDict[str, object] = OrderedDict()
    manifest["services"] = services
    if volumes:
        manifest["volumes"] = volumes
    if networks:
        manifest["networks"] = networks

    return manifest


def _format_scalar(value: object) -> str:
    if isinstance(value, bool):
        return "true" if value else "false"
    if value is None:
        return "null"
    if isinstance(value, (int, float)):
        return str(value)
    return json.dumps(str(value))


def _dump_list(items: list | tuple, indent: int) -> list[str]:
    indent_str = "  " * indent
    if not items:
        return [f"{indent_str}[]"]

    lines: list[str] = []
    for item in items:
        if isinstance(item, dict):
            if not item:
                lines.append(f"{indent_str}- {{}}")
            else:
                lines.append(f"{indent_str}-")
                lines.extend(_dump_dict(item, indent + 1))
        elif isinstance(item, (list, tuple)):
            if not item:
                lines.append(f"{indent_str}- []")
            else:
                lines.append(f"{indent_str}-")
                lines.extend(_dump_list(list(item), indent + 1))
        else:
            lines.append(f"{indent_str}- {_format_scalar(item)}")
    return lines


def _dump_dict(data: Mapping[str, object], indent: int) -> list[str]:
    indent_str = "  " * indent
    lines: list[str] = []
    for key, value in data.items():
        if isinstance(value, dict):
            if not value:
                lines.append(f"{indent_str}{key}: {{}}")
            else:
                lines.append(f"{indent_str}{key}:")
                lines.extend(_dump_dict(value, indent + 1))
        elif isinstance(value, (list, tuple)):
            if not value:
                lines.append(f"{indent_str}{key}: []")
            else:
                lines.append(f"{indent_str}{key}:")
                lines.extend(_dump_list(list(value), indent + 1))
        else:
            lines.append(f"{indent_str}{key}: {_format_scalar(value)}")
    return lines


def dump_yaml(data: Mapping[str, object]) -> str:
    """Serialize the manifest to a deterministic YAML string."""

    lines = _dump_dict(data, 0)
    return "\n".join(lines) + "\n"


def write_manifest(manifest: Mapping[str, object], path: Path = OUTPUT_FILE) -> None:
    yaml = dump_yaml(manifest)
    header = [
        "# ==================================================================================",
        "# WARNING: This file is auto-generated by compose/build.py",
        "# Do NOT edit this file manually. Instead, modify:",
        "#   - compose/build.py for service generation",
        "#   - Then run: python compose/build.py",
        "# ==================================================================================",
        "",
    ]
    content = "\n".join(header) + yaml
    path.write_text(content)


def main() -> None:
    env: dict[str, str] = load_env_with_override(REPO_ROOT)
    env.update(os.environ)

    web_containers, web_container_string = resolve_web_containers(env)
    backend_port = VAULT_WEB_PORT

    # Read HTTPS configuration from environment
    enable_https_raw = env.get("ENABLE_HTTPS", "").strip().lower()
    enable_https = enable_https_raw in ("true", "1", "yes", "on")
    ssl_cert_path = env.get("SSL_CERT_PATH", "").strip() or None
    ssl_key_path = env.get("SSL_KEY_PATH", "").strip() or None

    # Read HTTP and HTTPS port configuration
    http_port_raw = env.get("HTTP_PORT", "").strip()
    https_port_raw = env.get("HTTPS_PORT", "").strip()
    try:
        http_port = int(http_port_raw) if http_port_raw else 8080
        http_port = max(1, min(65535, http_port))
    except ValueError:
        http_port = 8080
    try:
        https_port = int(https_port_raw) if https_port_raw else 8443
        https_port = max(1, min(65535, https_port))
    except ValueError:
        https_port = 8443

    print(f"[compose] Leyzen Vault service")
    print(f"[compose] Number of replicas: {len(web_containers)}")
    print(f"[haproxy] HTTP port: {http_port}:80")
    if enable_https:
        print(f"[haproxy] HTTPS port: {https_port}:443")

    # Validate SSL certificates if HTTPS is enabled
    if enable_https:
        is_valid, warnings = validate_ssl_certificates(
            enable_https, ssl_cert_path, ssl_key_path, REPO_ROOT
        )
        if not is_valid:
            print("\n[warning] HTTPS is enabled but certificate validation failed:")
            for warning in warnings:
                print(f"         {warning}")
            print("         HAProxy will start but HTTPS may not work correctly.\n")
        else:
            print("[haproxy] HTTPS: enabled")
            if ssl_cert_path:
                print(f"[haproxy] SSL certificate: {ssl_cert_path}")
    else:
        print("[haproxy] HTTPS: disabled")

    ssl_cert_bundle_path: Path | None = None
    if enable_https and ssl_cert_path:
        ssl_cert_bundle_path, bundle_warnings = prepare_ssl_certificate_bundle(
            enable_https, ssl_cert_path, ssl_key_path, root_dir=REPO_ROOT
        )
        for warning in bundle_warnings:
            print(f"[warning] {warning}")
        if ssl_cert_bundle_path:
            print(f"[haproxy] SSL bundle: {ssl_cert_bundle_path}")

    # Prepare container paths for SSL certificates
    ssl_cert_path_container: str | None = None
    if enable_https and ssl_cert_path:
        ssl_cert_path_container = "/usr/local/etc/haproxy/ssl/cert.pem"

    # Check if orchestrator is enabled
    orchestrator_enabled_raw = env.get("ORCHESTRATOR_ENABLED", "true").strip().lower()
    orchestrator_enabled = orchestrator_enabled_raw in ("true", "1", "yes", "on")

    # Generate HAProxy configuration
    haproxy_config = render_haproxy_config_vault(
        web_containers,
        backend_port,
        enable_https=enable_https,
        ssl_cert_path=ssl_cert_path_container,
        orchestrator_enabled=orchestrator_enabled,
    )
    HAPROXY_CONFIG_PATH.parent.mkdir(parents=True, exist_ok=True)
    HAPROXY_CONFIG_PATH.write_text(haproxy_config)
    backend_summary = ", ".join(f"{name}:{backend_port}" for name in web_containers)
    print(
        f"[haproxy] Generated config for Leyzen Vault "
        f"({len(web_containers)} replica{'s' if len(web_containers) != 1 else ''})"
    )
    if backend_summary:
        print(f"[haproxy] Backends: {backend_summary}")
    manifest = build_compose_manifest(
        env,
        web_containers=web_containers,
        web_container_string=web_container_string,
        ssl_cert_bundle_path=ssl_cert_bundle_path,
    )

    write_manifest(manifest, OUTPUT_FILE)
    print(f"[compose] Wrote {OUTPUT_FILE}\n")


if __name__ == "__main__":
    main()
